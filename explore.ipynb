{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2768397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real phenotypes: 18\n",
      "First 10 phenotypes: ['23C', '25C', '27C', '30C', '33C', '35C', '37C', 'cu', 'suloc', 'ynb']\n",
      "Num synthetic phenos: 1\n",
      "TrainConfig defaults:\n",
      " TrainConfig(data_dir=PosixPath('data'), save_dir=PosixPath('models'), name_prefix='', phenotypes=['23C', '25C', '27C', '30C', '33C', '35C', '37C', 'cu', 'suloc', 'ynb', 'eth', 'gu', 'li', 'mann', 'mol', 'raff', 'sds', '4NQO'], optimizer='adam', patience=200, batch_size=64, learning_rate=0.001, lr_schedule=False, weight_decay=0.0, max_epochs=200, num_workers=1, gradient_clip_val=0.0, use_cache=True, use_modal=False, modal_detach=True, seed=None, synthetic_data=False)\n",
      "ModelConfig defaults:\n",
      " ModelConfig(model_type='rijal_et_al', seq_length=1164, embedding_dim=13, num_layers=3, init_scale=0.03, skip_connections=False, scaled_attention=False, layer_norm=False, dropout_rate=0.0, nhead=4, dim_feedforward=1048)\n"
     ]
    }
   ],
   "source": [
    "from analysis import dataset as ds\n",
    "from analysis.base import BaseModel, ModelConfig, TrainConfig\n",
    "\n",
    "print(\"Num real phenotypes:\", len(ds.phenotype_names))\n",
    "print(\"First 10 phenotypes:\", ds.phenotype_names[:10])\n",
    "print(\"Num synthetic phenos:\", len(getattr(ds, \"phenotype_names_synthetic\", [])))\n",
    "print(\"TrainConfig defaults:\\n\", TrainConfig())\n",
    "print(\"ModelConfig defaults:\\n\", ModelConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis.modified_rijal_et_al.ModifiedRijalEtAl(model_config: analysis.base.ModelConfig, train_config: analysis.base.TrainConfig)\n",
      "analysis.rijal_et_al.RijalEtAl(model_config: analysis.base.ModelConfig, train_config: analysis.base.TrainConfig)\n",
      "analysis.transformer.Transformer(model_config: analysis.base.ModelConfig, train_config: analysis.base.TrainConfig)\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "def all_subclasses(cls):\n",
    "    out = set()\n",
    "    work = [cls]\n",
    "    while work:\n",
    "        c = work.pop()\n",
    "        for sc in c.__subclasses__():\n",
    "            if sc not in out:\n",
    "                out.add(sc)\n",
    "                work.append(sc)\n",
    "    return sorted(out, key=lambda c: (c.__module__, c.__name__))\n",
    "\n",
    "\n",
    "subs = all_subclasses(BaseModel)\n",
    "for cls in subs:\n",
    "    try:\n",
    "        sig = str(inspect.signature(cls))\n",
    "    except ValueError:\n",
    "        sig = \"(...)\"\n",
    "    print(f\"{cls.__module__}.{cls.__name__}{sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedRijalEtAl      in (8, 1164) -> out (8, 4)\n",
      "Transformer            in (8, 1164) -> out (8, 4)\n",
      "RijalEtAl (single)     in (8, 1164) -> out (8, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitpro/miniconda3/envs/2025-geno-pheno-attention/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from analysis import dataset as ds\n",
    "from analysis.base import ModelConfig, TrainConfig\n",
    "from analysis.modified_rijal_et_al import ModifiedRijalEtAl\n",
    "from analysis.rijal_et_al import RijalEtAl\n",
    "from analysis.transformer import Transformer\n",
    "\n",
    "mc = ModelConfig(seq_length=1164, embedding_dim=16, num_layers=2, nhead=4, dim_feedforward=256)\n",
    "\n",
    "tc_multi = TrainConfig(phenotypes=ds.phenotype_names[:4])\n",
    "\n",
    "tc_single = TrainConfig(phenotypes=[ds.phenotype_names[0]])\n",
    "\n",
    "B = 8\n",
    "x = torch.randint(0, 3, (B, mc.seq_length)).float()\n",
    "\n",
    "models = [\n",
    "    (\"ModifiedRijalEtAl\", ModifiedRijalEtAl(model_config=mc, train_config=tc_multi)),\n",
    "    (\"Transformer\", Transformer(model_config=mc, train_config=tc_multi)),\n",
    "    (\"RijalEtAl (single)\", RijalEtAl(model_config=mc, train_config=tc_single)),\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, model in models:\n",
    "        y = model(x)\n",
    "        print(f\"{name:<22} in {tuple(x.shape)} -> out {tuple(y.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01d904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025-geno-pheno-attention",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
